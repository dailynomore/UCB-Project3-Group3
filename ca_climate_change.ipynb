{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wildfire Data\n",
    "# Name of the geojson file\n",
    "file_js = Path('Resources/California_Fire_Perimete.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load Wildfire GeoJSON Data\n",
    "wildfire_gdf = gpd.read_file(file_js)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   OBJECTID   YEAR_ STATE AGENCY UNIT_ID  FIRE_NAME   INC_NUM  \\\n",
      "0         1  2023.0    CA    CDF     SKU  WHITWORTH  00004808   \n",
      "1         2  2023.0    CA    LRA     BTU     KAISER  00010225   \n",
      "2         3  2023.0    CA    CDF     AEU    JACKSON  00017640   \n",
      "3         4  2023.0    CA    CDF     AEU     CARBON  00018821   \n",
      "4         5  2023.0    CA    CDF     AEU    LIBERTY  00018876   \n",
      "\n",
      "                      ALARM_DATE                      CONT_DATE  CAUSE  \\\n",
      "0  Sat, 17 Jun 2023 00:00:00 GMT  Sat, 17 Jun 2023 00:00:00 GMT    5.0   \n",
      "1  Fri, 02 Jun 2023 00:00:00 GMT  Fri, 02 Jun 2023 00:00:00 GMT    5.0   \n",
      "2  Sat, 01 Jul 2023 00:00:00 GMT  Sun, 02 Jul 2023 00:00:00 GMT    2.0   \n",
      "3  Tue, 11 Jul 2023 00:00:00 GMT  Tue, 11 Jul 2023 00:00:00 GMT    9.0   \n",
      "4  Tue, 11 Jul 2023 00:00:00 GMT  Wed, 12 Jul 2023 00:00:00 GMT   14.0   \n",
      "\n",
      "   C_METHOD  OBJECTIVE  GIS_ACRES COMMENTS COMPLEX_NAME  \\\n",
      "0       1.0        1.0   5.729125     None         None   \n",
      "1       1.0        1.0  13.602380     None         None   \n",
      "2       1.0        1.0  27.814460     None         None   \n",
      "3       1.0        1.0  58.760230     None         None   \n",
      "4       1.0        1.0  70.979000     None         None   \n",
      "\n",
      "                                  IRWINID FIRE_NUM COMPLEX_ID  DECADES  \\\n",
      "0  {7985848C-0AC2-4BA4-8F0E-29F778652E61}     None       None   2020.0   \n",
      "1  {43EBCC88-B3AC-48EB-8EF5-417FE0939CCF}     None       None   2020.0   \n",
      "2  {B64E1355-BF1D-441A-95D0-BC1FBB93483B}     None       None   2020.0   \n",
      "3  {CB41DB0A-E4B1-489D-A4EA-738F2CD6DB3B}     None       None   2020.0   \n",
      "4  {F83F70A4-07A7-40B8-BD51-10CCC1C30D63}     None       None   2020.0   \n",
      "\n",
      "                                            geometry  \n",
      "0  POLYGON ((-13682443 5091132.739, -13682445.825...  \n",
      "1  POLYGON ((-13576727.142 4841226.161, -13576726...  \n",
      "2  POLYGON ((-13459243 4621236, -13458968 4621453...  \n",
      "3  POLYGON ((-13468077 4642260, -13467975 4642332...  \n",
      "4  POLYGON ((-13468418 4614853, -13468428 4614801...  \n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows to understand the structure\n",
    "print(wildfire_gdf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Names: Index(['OBJECTID', 'YEAR_', 'STATE', 'AGENCY', 'UNIT_ID', 'FIRE_NAME',\n",
      "       'INC_NUM', 'ALARM_DATE', 'CONT_DATE', 'CAUSE', 'C_METHOD', 'OBJECTIVE',\n",
      "       'GIS_ACRES', 'COMMENTS', 'COMPLEX_NAME', 'IRWINID', 'FIRE_NUM',\n",
      "       'COMPLEX_ID', 'DECADES', 'geometry'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Extract column names\n",
    "column_names = wildfire_gdf.columns\n",
    "print(\"Column Names:\", column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year Range: 1878.0 to 2023.0\n"
     ]
    }
   ],
   "source": [
    "# Check the minimum and maximum year in the dataset\n",
    "min_year = wildfire_gdf['YEAR_'].min()\n",
    "max_year = wildfire_gdf['YEAR_'].max()\n",
    "\n",
    "print(f\"Year Range: {min_year} to {max_year}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Process Wildfire Data - Change column names\n",
    "# Rename specific columns\n",
    "wildfire_gdf = wildfire_gdf.rename(columns={\n",
    "    'OBJECTID': 'ID',\n",
    "    'YEAR_': 'Year',\n",
    "    'STATE': 'State',\n",
    "    'AGENCY': 'Agency',\n",
    "    'UNIT_ID': 'Unit ID',\n",
    "    'FIRE_NAME': 'Fire Name',\n",
    "    'INC_NUM': 'Incident Number',\n",
    "    'ALARM_DATE': 'Alarm Date',\n",
    "    'CONT_DATE': 'Containment Date',\n",
    "    'CAUSE': 'Cause',\n",
    "    'C_METHOD': 'Collection Method',\n",
    "    'OBJECTIVE': 'Management Objective',\n",
    "    'GIS_ACRES': 'GIS Acres',\n",
    "    'COMMENTS': 'Comments', \n",
    "    'COMPLEX_NAME': 'Complex Name',\n",
    "    'IRWINID': 'IRWIN ID',\n",
    "    'FIRE_NUM': 'Fire Number',\n",
    "    'COMPLEX_ID': 'Complex ID',\n",
    "    'DECADES':'Decades', \n",
    "    'geometry': 'Geometry'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Names: Index(['ID', 'Year', 'State', 'Agency', 'Unit ID', 'Fire Name',\n",
      "       'Incident Number', 'Alarm Date', 'Containment Date', 'Cause',\n",
      "       'Collection Method', 'Management Objective', 'GIS Acres', 'Comments',\n",
      "       'Complex Name', 'IRWIN ID', 'Fire Number', 'Complex ID', 'Decades',\n",
      "       'Geometry'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Confirm column name changes\n",
    "column_names = wildfire_gdf.columns\n",
    "print(\"Column Names:\", column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keep only a subset of columns for analysis\n",
    "wildfire_gdf = wildfire_gdf[['ID', 'Year', 'State', 'Agency', 'Unit ID', 'Fire Name',\n",
    "    'Incident Number', 'Alarm Date', 'Containment Date', 'Cause', 'GIS Acres', \n",
    "    'Comments','Complex Name', 'Fire Number', 'Decades','Geometry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the centroid of each geometry (for polygons)\n",
    "wildfire_gdf['Centroid'] = wildfire_gdf['Geometry'].centroid\n",
    "\n",
    "# Extract latitude and longitude from the centroid\n",
    "wildfire_gdf['Latitude'] = wildfire_gdf['Centroid'].y\n",
    "wildfire_gdf['Longitude'] = wildfire_gdf['Centroid'].x\n",
    "\n",
    "# Convert the geometry column to WKT (Well-Known Text)\n",
    "wildfire_gdf['Geometry'] = wildfire_gdf['Geometry'].apply(lambda x: x.wkt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check transformed data\n",
    "print(wildfire_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check all columns\n",
    "column_names = wildfire_gdf.columns\n",
    "print(\"Column Names:\", column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "# Rainfall SF Data\n",
    "# Name of the rainfall csv file\n",
    "sf_rain= Path('Resources/sf_rainfall.csv')\n",
    "# The correct encoding must be used to read the CSV in pandas\n",
    "df_sf_rain = pd.read_csv(sf_rain)\n",
    "# Preview of the rain fall dataFrame\n",
    "df_sf_rain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "# Rainfall LA Data\n",
    "# Name of the rainfall csv file\n",
    "la_rain= Path('Resources/la_rainfall.csv')\n",
    "# The correct encoding must be used to read the CSV in pandas\n",
    "df_la_rain = pd.read_csv(la_rain)\n",
    "# Preview of the rain fall dataFrame\n",
    "df_la_rain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Precipitation (inches)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1896</td>\n",
       "      <td>26.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1897</td>\n",
       "      <td>27.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1898</td>\n",
       "      <td>17.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1899</td>\n",
       "      <td>20.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1900</td>\n",
       "      <td>24.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Precipitation (inches)\n",
       "0  1896                   26.42\n",
       "1  1897                   27.07\n",
       "2  1898                   17.29\n",
       "3  1899                   20.19\n",
       "4  1900                   24.48"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rainfall San Diego Data\n",
    "# Name of the rainfall csv file\n",
    "sdg_rain= Path('Resources/sdg_rainfall.csv')\n",
    "# The correct encoding must be used to read the CSV in pandas\n",
    "df_sdg_rain = pd.read_csv(sdg_rain)\n",
    "# Preview of the rain fall dataFrame\n",
    "df_sdg_rain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine all rainfall data\n",
    "df_rain = pd.concat([df_sf_rain, df_la_rain, df_sdg_rain], axis=0, ignore_index=True)\n",
    "df_rain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rainfall Station Geo Data\n",
    "# Name of the rainfall station geo csv file\n",
    "rainfall_station = Path('Resources/weather_station_geo.csv')\n",
    "# The correct encoding must be used to read the CSV in pandas\n",
    "df_rain_geo = pd.read_csv(rainfall_station)\n",
    "# Preview of the rain fall dataFrame\n",
    "df_rain_geo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change Rainfall Station Geo Data to be consistent with df_rain data for merge later\n",
    "df_rain_geo.columns = ['STATION NAME', 'STATION_ID', 'ELEV (FEET)', 'LATITUDE', 'LONGITUDE',\n",
    "'COUNTY', 'OPERATOR AGENCY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inspect mergered data\n",
    "df_precip = pd.merge(df_rain, df_rain_geo, on='STATION_ID', how = 'left')\n",
    "df_precip.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform date columns to the correct datetime format\n",
    "df_precip['DATE TIME']=pd.to_datetime(df_precip['DATE TIME'])\n",
    "df_precip['OBS DATE']=pd.to_datetime(df_precip['OBS DATE'])\n",
    "df_precip.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column with just the year and month in datetime format\n",
    "df_precip['YEAR MONTH'] = df_precip['DATE TIME'].dt.to_period('M').dt.to_timestamp()\n",
    "df_precip.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average Temperature Data\n",
    "sf_temp_path = Path('Resources/avg-temps-sf.csv')\n",
    "la_temp_path = Path('Resources/avg-temps-la.csv')\n",
    "sd_temp_path = Path('Resources/avg-temps-sd.csv')\n",
    "sac_temp_path = Path('Resources/avg-temps-sac.csv')\n",
    "bf_temp_path = Path('Resources/avg-temps-bf.csv')\n",
    "erk_temp_path = Path('Resources/avg-temps-erk.csv')\n",
    "ca_temp_path = Path('Resources/avg-temps-ca.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in CSVs without unnecessary rows\n",
    "sf_temps_df = pd.read_csv(sf_temp_path, skiprows=3)\n",
    "la_temps_df = pd.read_csv(la_temp_path, skiprows=3)\n",
    "sd_temps_df = pd.read_csv(sd_temp_path, skiprows=3)\n",
    "sac_temps_df = pd.read_csv(sac_temp_path, skiprows=3)\n",
    "bf_temps_df = pd.read_csv(bf_temp_path, skiprows=3)\n",
    "erk_temps_df = pd.read_csv(erk_temp_path, skiprows=3)\n",
    "ca_temps_df = pd.read_csv(ca_temp_path, skiprows=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of all city dfs\n",
    "cities_temps = [sf_temps_df, la_temps_df, sd_temps_df, sac_temps_df, bf_temps_df, erk_temps_df, ca_temps_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date to datetime format and split year and month into two columns, then drop 'Date' column\n",
    "for city in cities_temps:\n",
    "    city['date'] = pd.to_datetime(city['Date'], format='%Y%m')\n",
    "    city['month'] = city['date'].dt.month\n",
    "    city['year'] = city['date'].dt.year\n",
    "    city = city.drop('Date', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop 'date' column in each df\n",
    "for city in cities_temps:\n",
    "    city = city.drop('date', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename each 'Value' column to 'temperature'\n",
    "sf_temps_df = sf_temps_df.rename(columns={'Value': 'temperature'})\n",
    "la_temps_df = la_temps_df.rename(columns={'Value': 'temperature'})     \n",
    "sd_temps_df = sd_temps_df.rename(columns={'Value': 'temperature'})     \n",
    "sac_temps_df = sac_temps_df.rename(columns={'Value': 'temperature'})     \n",
    "bf_temps_df = bf_temps_df.rename(columns={'Value': 'temperature'})     \n",
    "erk_temps_df = erk_temps_df.rename(columns={'Value': 'temperature'}) \n",
    "ca_temps_df = ca_temps_df.rename(columns={'Value': 'temperature'})  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder each df\n",
    "sf_temps_df = sf_temps_df[['year', 'month', 'temperature']]\n",
    "la_temps_df = la_temps_df[['year', 'month', 'temperature']]\n",
    "sd_temps_df = sd_temps_df[['year', 'month', 'temperature']]\n",
    "sac_temps_df = sac_temps_df[['year', 'month', 'temperature']]\n",
    "bf_temps_df = bf_temps_df[['year', 'month', 'temperature']]\n",
    "erk_temps_df = erk_temps_df[['year', 'month', 'temperature']]\n",
    "ca_temps_df = ca_temps_df[['year', 'month', 'temperature']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check each df\n",
    "print(sf_temps_df)\n",
    "print(la_temps_df)\n",
    "print(sd_temps_df)\n",
    "print(sac_temps_df)\n",
    "print(bf_temps_df)\n",
    "print(erk_temps_df)\n",
    "print(ca_temps_df)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "nteract": {
   "version": "0.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
